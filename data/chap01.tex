% !TeX root = ../main.tex

\chapter{引言}
\label{cha:intro}

\section{研究背景及意义}
近年来，深度学习的方法许多计算机视觉任务中都取得了很好的表现，例如图像分类\cite{he2016deep,krizhevsky2012imagenet}、目标检测\cite{ren2015faster}、动作识别\cite{wang2016temporal,tran2018closer,carreira2017quo}等。虽然许多深度模型在这些任务上达到了与人类相当甚至超过人类的水平，但在这些任务中，模型仅仅需要具有对视觉信息的\emph{感知}能力即可胜任。然而，在更多的真实场景中，视觉信息十分复杂，而且常常需要结合人类的常识进行推理。大部分的传统模型并不具备处理这种复杂输入的能力。为了解决这个问题，学者们开始越来越关注模型对视觉信息的\emph{推理}能力，并提出了各种各样的视觉推理任务。

视觉问答（Visual Question Answering, VQA）是最早兴起的一类视觉推理任务\cite{antol2015vqa}。在VQA中，模型的输入是一张真实图片和一个对应的问题。然而在最初的 VQA 数据集\cite{antol2015vqa} 中，模型并没有真正地学会推理的过程，而是学到了某些捷径\cite{johnson2017clevr}。例如，在问题“地面上覆盖的是什么”中，模型学会了回答“雪”并不是因为模型理解了这个问题，而是因为在这个数据集中，图中有雪的问题常常会和“地面”有关。也就是说模型通过有偏的数据集学到的知识也是不可靠的，更没有对推理建模的过程。为了解决这个问题，Johnson \etal \cite{johnson2017clevr} 提出了 CLEVR 数据集，用于诊断 VQA 模型的推理能力。CLEVR 数据集中的图片都是人工合成的，包括一些简单的三维图形。其问题也是自动生成的，并附有与之对应的执行程序。在已知场景的情况下，可以直接执行程序得到准确的答案。所以，很多工作的重点放在了如何从图片中解析场景的属性以及从问题的自然语言生成准确的程序\cite{Johnson_2017_ICCV,yi2018neural,vedantam2019probabilistic}。另一方面，Goyal \etal\cite{goyal2017making}提出通过平衡数据来消除偏置，从而得到VQAv2数据集。除了视觉问答，还有一系列相关工作以问答的方式构建推理任务，例如视觉常识推理\cite{zellers2019recognition}，电影推理\cite{tapaswi2016movieqa}等等。然而这些任务中，自然语言起到了很大的辅助作用，甚至直接表示出了推理的过程。

为了解决这个问题，本文提出了视频溯因常识推理（Video Abductive Commonsense Reasoning, VACR）。模型需要从表示开始和结束状态的两张图片推理出中间最可能的动作序列，在这个任务中，模型的输入只有两个观测图片和多个候选选项，每个选项由一系列的视频片段构成。也就是说模型只接受视觉信息的输入，而没有任何自然语言的辅助信息。同时，这些视觉信息都是来自于真实世界的视频而不是人工合成的图片，所以更加考验模型对常识的理解和推理能力。实验发现，一些传统的视频理解模型在本文提出的任务上表现较差，这表明了现有模型在对真实世界中的视频进行推理的能力还有待提高。本文也会为了解决 VACR 任务在模型的设计上进行探索。

本文提出的 VACR 任务具有广泛的应用前景和意义。一个最直观的应用就是机器人的动作决策问题。如果机器人能够很好地完成 VACR 任务，那么它就可以在给定初始和目标状态时，在多个可能的决策序列中选出一个最优策略。与机器人传统的决策任务不同，这里提到的决策需要更多与真实世界中复杂场景的物理交互。此外，机器人还可以从大量的教程类视频中学习到很多常识性的知识，从而变得更加智能。

\section{本文创新点}
本文的创新点主要包含以下三个部分。
\subsection{视频溯因常识推理}
为了解决传统的视觉推理任务中存在的问题，本文提出了全新的任务：视频溯因常识推理（Video Abductive Commonsense Reasoning, VACR）。该任务的总体架构建立在溯因推理上，即给定两个观测$O_1$和$O_2$ 和一个候选假设集合$\gH = \{H_i\}$。候选假设集合$\gH$中包含了一个正确选项$H_+$和多个错误选项$\{H_-\}$。模型需要根据这两个观测来选出最有可能的假设。具体来说，在\VACR 任务中，$O_1$ 和 $O_2$ 分别为开始状态和结束状态的图片，而每一个 $H_i$ 则由一系列步骤构成，每个步骤用一个视频片段来表示。该任务能够很好地检验模型对复杂的视觉信息进行推理的能力。
\subsection{VideoABC数据集}
本文提出了一个视频溯因常识推理数据集 VideoABC（Video ABductive Commonsense Reasoning），该数据集以一个教程类视频数据集COIN\cite{tang2019coin} 为基础构建而成。本文首先对 COIN 数据集进行了二次标注，保证了推理过程的连续性；再基于视频溯因常识推理的任务设定，构建了 VideoABC 数据集。为了去除过于简单的假设，本文使用预训练的模型进行了难样本的挖掘（Hard Sample Mining）。实验表明，很多在视频分类方面最先进的模型都没有取得很好的效果\cite{tran2018closer,wang2016temporal,carreira2017quo}。
\subsection{HDR Net}
为了提高模型在视频溯因常识推理任务上的性能，本文提出了一个全新的网络： HDR Net（Hierarchical Dual Reasoning Network, 多级双重推理网络）。该网络包括两个重要的组成模块：步内推理模块（Intra-step Reasoning Module，IRM）模块和步间推理模块（Cross-step Reasoning，CRM）。HDR Net 以 ResNet18\cite{he2016deep} 为主干网络，并在每个池化层后加入IRM和CRM两个模块。所以，HDR Net 可以在提取空间特征的同时进行时序上的推理。实验表明，该网络在 VideoABC 数据集上的正确率高达 85.2\%。

\section{本文结构}
本文后续章节的内容将从以下几个方面展开介绍：在第~\ref{cha:related_work}~章中，本文将介绍一些相关的工作，包括之前的视觉推理任务、教程类视频以及视频分析理解的相关方法；在第~\ref{cha:vacr}~章中，本文将正式给出视频溯因常识推理的定义；在第~\ref{cha:VideoABC}~章中，本文将详细介绍VideoABC数据集的构建方式；在第~\ref{cha:experimetns}~章中，本文将展示并分析VideoABC数据集上的相关实验结果；最后在第~\ref{cha:close}~章对全文进行总结。