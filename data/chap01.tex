% !TeX root = ../main.tex

\chapter{引言}
\label{cha:intro}

\section{研究背景及意义}
近年来，深度学习的方法许多计算机视觉任务中都取得了很好的表现，例如图像分类\cite{he2016deep,krizhevsky2012imagenet}、目标检测\cite{}、语义分割\cite{}、动作识别\cite{}等。虽然许多深度模型在这些任务上达到了与人类相当甚至超过人类的水平，但在这些任务中，模型仅仅需要具有对视觉信息的\emph{感知}能力即可胜任。然而，在更多的真实场景中，视觉信息十分复杂，而且常常需要结合人类的常识进行推理。大部分的传统模型并不具备处理这种复杂输入的能力。为了解决这个问题，学者们开始越来越关注模型对视觉信息的\emph{推理}能力，并提出了各种各样的视觉推理任务。视觉问答（Visual Question Answering, VQA）是最早兴起的一类视觉推理任务\cite{}。在VQA中，模型的输入是一张真实图片和一个对应的问题。然而在最初的 VQA 数据集\cite{} 中，模型并没有真正地学会推理的过程，而是学到了某些捷径\cite{johnson2017clevr}。例如，在问题“地面上覆盖的是什么”中，模型学会了回答“雪”并不是因为模型理解了这个问题，而是因为在这个数据集中，图中有雪的问题常常会和“地面”有关。也就是说模型通过有偏的数据集学到的知识也是不可靠的，更没有对推理建模的过程。为了解决这个问题，Johnson \etal \cite{johnson2017clevr} 提出了 CLEVR 数据集，用于诊断 VQA 模型的推理能力。CLEVR 数据集中的图片都是人工合成的，包括一些简单的三维图形。其问题也是自动生成的，并附有与之对应的执行程序。在已知场景的情况下，可以直接执行程序得到准确的答案。所以，很多工作的重点放在了如何从图片中解析场景的属性以及从问题的自然语言生成准确的程序\cite{Johnson_2017_ICCV,yi2018neural,vedantam2019probabilistic}。另一方面，


\section{现有研究概述}
\section{本文创新点}