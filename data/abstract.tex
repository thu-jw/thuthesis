% !TeX root = ../main.tex

% 中英文摘要和关键字

\begin{abstract}
  深度学习的方法在分类、检测等视觉任务中取得了很好的表现。但是，这些任务主要体现了模型的感知能力，而没有涉及到推理能力。近年来，研究人员们越来越关注对模型推理能力的探索，并提出了一系列与视觉推理相关的任务，例如视觉问答、视觉常识推理等。然而在这些任务中，模型常常可以从问题中的自然语言直接或间接得到推理过程，而没有真正地学会如何进行推理。为了解决这个问题，本文基于教程类视频提出了一个全新的任务：视频溯因常识推理。在这个任务中，模型需要基于初始和结束状态的图片来选出之间的最可能发生的动作序列。模型的输入不包含任何自然语言，所以不会从问题本身获得推理过程的提示。
  
  本文在一个教程类视频数据集 COIN 的基础上进行二次标注，构建了视频溯因常识推理数据集（VideoABC）。在该数据集上，很多在视频理解方面最先进的模型都没有取得很好的效果。为此，本文提出了一个全新多级双重推理模块。该模块可以在不同的分辨率等级上依次进行步骤内和步骤间的推理。基于该模块构建的网络（HDR Net）在本文提出的数据集上取得了 86.1\% 的准确率，比基础模型高出 8\%. 

  本文的创新点主要有：
  \begin{enumerate}
    \item 提出了一个全新的视觉推理任务：视频溯因常识推理；
    \item 构建了一个视觉溯因常识推理数据集 VideoABC；
    \item 提出了一个新的推理模型，并在 VideoABC 上取得了目前最高的准确率。
  \end{enumerate}

  % 关键词用“英文逗号”分隔
  \thusetup{
    keywords = {溯因推理, 视觉推理, 计算机视觉, 深度学习},
  }
\end{abstract}

\begin{abstract*}
  Deep learning methods has achieved marvelous performance in a lot of visual tasks such as classification and detection. However, theses visual tasks mainly reveal the perception ability of the models rather than the reasoning ability. In recent years, researchers starts to pay more and more attention to explore the reasoning ability of the models and propose a series of visual tasks related to visual reasoning like Visual Question Answering, Visual Commonsense Reasoning, \textit{etc.} Nevertheless, models can get access to the reasoning process directly or indirectly from the natural language in the question in these task rather than really learn how to perform reasoning. To overcome that, we propose a novel task based on instructional videos: video abductive commonsense reasoning. In this task, the model need to choose the most plausible action sequence based on the images representing the beginning and the ending state. The model take no natural language as input, therefore can't obtain clue of the reasoning process from the question itself.

  We perform re-annotation based on a instructional video dataset COIN to construct our video abductive reasoning dataset VideoABC, where most of the state-of-the-art models in video understanding fail. Therefore, we propose a novel hierarchical dual reasoning module, which performs intra-step and cross-step reasoning at different resolutions. The neural network based on this module (HDR Net) achieves the accuracy of 86.1\% on VideoABC dataset, which is higher than the baseline method by 8\%.

  The contribution of this article are listed as follows:
  \begin{enumerate}
    \item We propose a novel visual reasoning task：Video Abductive Commonsense Reasoning;
    \item We construct a dataset called VideoABC;
    \item We propose a novel reasoning model which achieves the best performance on VideoABC.
  \end{enumerate}
  \thusetup{
    keywords* = {Abductive reasoning, Visual reasoning, Computer vision, Deep learning},
  }
\end{abstract*}
