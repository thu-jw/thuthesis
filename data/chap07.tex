% !TeX root = ../main.tex

\chapter{总结}\label{cha:close}
为了解决当前视觉推理任务中存在的一些问题，本文提出了一个新的视觉推理任务：视频溯因常识推理，在该任务中，模型需要根据表示开始状态和结束状态的两个观测$O_1$和$O_2$从候选假设集合$\{H_i\}$中选出正确答案，其中每个假设由一系列基本步骤构成，而每个步骤以一个视频片段的形式呈现。

根绝视频溯因常识推理的任务定义，本文构建了VideoABC数据集。该数据集以教程类数据集COIN\cite{tang2019coin}为基础，通过二次标注保证了推理过程的连续性，并通过预定义的四种错误类型构建出候选假设集合，最后使用难分样本挖掘的方式来去除过于简单的假设，从而提升VideoABC数据集的难度。最后的VideoABC数据集中共包含13,522个问题，最大的推理时长高达731s，这对模型完成长时间推理的能力来说是一个很大的挑战。

实验发现，大部分在视频理解上表现较好的模型都不能在VideoABC数据集上取得很好的效果。为此，本文针对视频溯因常识推理任务设计了一个新的模型：多级双重推理网络（HDR Net）。该网络以ResNet18\cite{he2016deep}为基础，在每个空间的池化层后面都加入一个步骤内推理模块和步骤间推理模块，从而能够有效地挖掘步骤内和步骤间的时序关系。步骤内和步骤间推理模块都使用双向RNN的结构，并使用残差连接的方式来更新特征。实验表明，HDR Net在VideoABC上的表现远超其他的模型。

此外，为了检验人类在VideoABC数据集上的表现，本文开发了在线测试工具，发现人类的表现比当前现有的模型（包括HDR Net）都要高，这表明人类基于已有的常识和推理能力能够很好地胜任视频溯因常识推理任务，也说明了在VideoABC数据集上模型还有很大的进步空间。